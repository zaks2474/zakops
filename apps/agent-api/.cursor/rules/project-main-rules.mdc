---
alwaysApply: true
---

# LangGraph FastAPI AI Agent Development

You are an expert in building production-ready AI agent applications using Python, FastAPI, LangGraph, and LangChain.

This is a **LangGraph FastAPI Agent Project** for building scalable, secure AI agent services with LLM orchestration, observability, and persistence.

## Project Architecture Overview

This is an AI agent application that:

- Uses **LangGraph** for building stateful, multi-step AI agent workflows
- Uses **FastAPI** for high-performance async REST API endpoints
- Integrates **Langfuse** for LLM observability and tracing
- Uses **PostgreSQL** with **pgvector** for long-term memory storage (mem0ai)
- Implements **JWT authentication** with session management
- Provides **rate limiting** with slowapi
- Includes **Prometheus metrics** and **Grafana dashboards** for monitoring
- Uses **structlog** for structured logging with environment-specific formatting
- Implements **retry logic** using tenacity library
- Uses **rich** library for colored, formatted console outputs

## Key Principles

- Write concise, technical responses with accurate Python examples
- Use functional, declarative programming; avoid classes where possible except for services and agents
- Prefer iteration and modularization over code duplication
- Use descriptive variable names with auxiliary verbs (e.g., `is_active`, `has_permission`)
- Use lowercase with underscores for directories and files (e.g., `routers/user_routes.py`)
- Favor named exports for routes and utility functions
- Use the Receive an Object, Return an Object (RORO) pattern
- **All imports must be at the top of the file** - never add imports inside functions or classes

## Python/FastAPI Conventions

- Use `def` for pure functions and `async def` for asynchronous operations
- Use type hints for all function signatures; prefer Pydantic models over raw dictionaries
- File structure: exported router, sub-routes, utilities, static content, types (models, schemas)
- Use concise, one-line syntax for simple conditional statements (e.g., `if condition: do_something()`)
- Avoid unnecessary else statements; use the if-return pattern instead

## LangGraph & LangChain Integration

- Use LangGraph `StateGraph` for building AI agent workflows with multiple steps/nodes
- Define clear state schemas using Pydantic models (see `app/schemas/graph.py`)
- Use `CompiledStateGraph` for production workflows
- Implement `AsyncPostgresSaver` for checkpointing and persistence
- Use LangChain's `CallbackHandler` from Langfuse for tracing LLM calls
- Structure agents as classes that manage graph creation and execution (see `app/core/langgraph/graph.py`)
- Use `Command` for controlling graph flow between nodes
- Implement proper streaming responses for long-running agent operations

## Long-Term Memory (mem0ai)

- Use mem0ai's `AsyncMemory` for semantic memory storage
- Configure with pgvector as the vector store backend
- Store memories per user_id for personalized experiences
- Use async methods: `add()`, `get()`, `search()`, `delete()`
- Configure memory collection name via environment variables

## Error Handling and Validation

Prioritize error handling and edge cases:

- Handle errors and edge cases at the beginning of functions
- Use early returns for error conditions to avoid deeply nested if statements
- Place the happy path last in the function for improved readability
- Use guard clauses to handle preconditions and invalid states early
- Implement proper error logging with structured logging
- Use `HTTPException` for expected errors with appropriate status codes
- Use middleware for handling unexpected errors globally

## Logging Standards

Use structlog for all logging with these conventions:

- Log messages must be **lowercase and separated by underscores** (e.g., `"user_login_successful"`)
- **No f-strings in structlog events** - pass all variables as kwargs for proper filtering
- Use `logger.exception()` instead of `logger.error()` to preserve tracebacks
- For warnings with exceptions, use `exc_info=True`: `logger.warning("event_name", exc_info=True)`
- Always bind context to logs: session_id, user_id, request_id, etc.
- Use appropriate log levels: `debug`, `info`, `warning`, `error`, `exception`
- Example: `logger.info("chat_request_received", session_id=session.id, message_count=len(messages))`

## Rich Library for Outputs

- **Always enable rich library** for formatted console outputs
- Use rich for progress bars, tables, panels, and formatted text
- Use rich.console for debugging complex data structures
- Apply rich formatting for evaluation reports and CLI outputs

## Retry Logic

- **Always use tenacity library** for retry logic
- Configure retries with exponential backoff
- Set appropriate stop conditions (max attempts, max time)
- Log retry attempts for observability
- Example: `@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))`

## Caching Strategy

- **Only cache successful responses**, never cache errors
- Use appropriate cache TTL based on data volatility
- Implement cache invalidation strategies
- Consider using Redis or in-memory caches for frequently accessed data
- Document cache keys and expiration policies

## Dependencies

Core dependencies in this project:

- **FastAPI** - Web framework
- **LangGraph** - Agent workflow orchestration
- **LangChain** - LLM abstraction and tools
- **Langfuse** - LLM observability and tracing
- **Pydantic v2** - Data validation and settings
- **structlog** - Structured logging
- **mem0ai** - Long-term memory management
- **PostgreSQL** with **pgvector** - Database and vector storage
- **SQLModel** - ORM for database models
- **tenacity** - Retry logic
- **rich** - Terminal formatting
- **slowapi** - Rate limiting
- **prometheus-client** - Metrics collection

## FastAPI-Specific Guidelines

- Use functional components (plain functions) and Pydantic models for validation
- Use declarative route definitions with clear return type annotations
- **Use lifespan context managers** for startup/shutdown (avoid `@app.on_event`)
- Use dependency injection for services, database connections, and auth
- Apply rate limiting decorators to all endpoints: `@limiter.limit(settings.RATE_LIMIT_ENDPOINTS["endpoint_name"][0])`
- Use middleware for logging context, metrics, and error handling
- Implement proper CORS configuration via settings
- Structure routes in versioned API modules (e.g., `app/api/v1/`)

## Authentication & Security

- Use JWT tokens for authentication
- Implement session-based user management (see `app/api/v1/auth.py`)
- Use `get_current_session` dependency for protected endpoints
- Store sensitive data in environment variables, never in code
- Implement proper CORS and rate limiting
- Validate all user inputs with Pydantic models

## Database & Persistence

- Use SQLModel for ORM models (combines SQLAlchemy + Pydantic)
- Define models in `app/models/` directory
- Use async database operations with asyncpg
- Implement proper connection pooling
- Use LangGraph's AsyncPostgresSaver for agent checkpointing
- Implement health checks for database connectivity

## Performance Optimization

- Minimize blocking I/O operations; use async for all database and external API calls
- Implement caching for static and frequently accessed data
- Use connection pooling for database connections
- Optimize LLM calls with streaming responses for better UX
- Monitor performance with Prometheus metrics
- Use lazy loading for large datasets

## Observability & Monitoring

- Integrate Langfuse for LLM tracing on all agent operations
- Export Prometheus metrics for API performance, rate limits, and system resources
- Use structured logging with context binding (request_id, session_id, user_id)
- Implement health check endpoints (`/health`)
- Configure Grafana dashboards for visualization
- Track LLM inference duration, token usage, and costs

## Testing & Evaluation

- Implement metric-based evaluations for LLM outputs (see `evals/` directory)
- Create custom evaluation metrics as markdown files in `evals/metrics/prompts/`
- Use Langfuse traces for evaluation data sources
- Generate JSON reports with success rates and detailed metrics
- Use interactive CLI with rich formatting for running evaluations

## Configuration Management

- Use environment-specific configuration files (`.env.development`, `.env.staging`, `.env.production`)
- Use Pydantic Settings for type-safe configuration (see `app/core/config.py`)
- Define environment enum for environment-specific behavior
- Never hardcode secrets or API keys
- Use appropriate defaults for development environments

## Key Conventions

1. All routes must have rate limiting decorators
2. All LLM operations must have Langfuse tracing
3. All async operations must have proper error handling
4. All logs must follow structured logging format with lowercase_underscore event names
5. All retries must use tenacity library
6. All console outputs should use rich formatting
7. All caching should only store successful responses
8. All imports must be at the top of files
9. All database operations must be async
10. All endpoints must have proper type hints and Pydantic models

## Project Structure

```markdown
app/
├── api/v1/          # API routes (auth, chatbot, etc.)
├── core/            # Core functionality (config, logging, metrics, middleware)
│   ├── langgraph/   # LangGraph agent and tools
│   └── prompts/     # System prompts for agents
├── models/          # SQLModel database models
├── schemas/         # Pydantic schemas for API and graph state
├── services/        # Business logic services (llm, database)
└── utils/           # Utility functions
```markdown

Refer to LangGraph, LangChain, FastAPI, and Langfuse documentation for best practices.
  